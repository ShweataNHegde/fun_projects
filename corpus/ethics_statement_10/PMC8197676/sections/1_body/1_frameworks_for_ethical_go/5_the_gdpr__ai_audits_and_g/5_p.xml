<?xml version="1.0" encoding="UTF-8"?>
<p id="Par57">Guidance and frameworks can also be derived from related areas for example in the UK government guidance on producing quality analysis for government, the AQuA book [
 <xref ref-type="bibr" rid="CR40">40</xref>], and governmental recommendations for Business Critical models. It is expected that a model would have a suite of robust supporting paperwork, the burden being higher for business critical models. This guidance was developed post the 2013 MacPherson Review [
 <xref ref-type="bibr" rid="CR57">57</xref>] to ensure fit for purpose modelling and could easily be updated and developed for AI, particularly for those in high risk scenarios such as healthcare, along with recommendations from ethics committees and, in particular, the House of Lords Committee on AI. Indeed, as stated earlier, frameworks for best practise data quality also exist and so, if already adhered to, should not provide further unnecessary burden [
 <xref ref-type="bibr" rid="CR58">58</xref>]. Legislation for AI systems and mandated regulation, beyond that of data privacy and protection, is also beginning to occur. Most are addressing certain types of AI systems (such as Lethal Autonomous Weapons or self-driving cars) though wider more general AI laws are beginning to be enacted in other countries [
 <xref ref-type="bibr" rid="CR41">41</xref>].
</p>
