<?xml version="1.0" encoding="UTF-8"?>
<p id="Par4">In the UK, August 2020 was a pivotal month in light of a number of legal cases and decisions challenging the use of some AI and machine learning systems. Examples include the judgement of the UK government visa streaming algorithm in August 2020 and its resultant suspension [
 <xref ref-type="bibr" rid="CR3">3</xref>]. This landmark legal challenge highlighted the human rights and equalities that can be caused by some AI systems [
 <xref ref-type="bibr" rid="CR4">4</xref>]. Similarly, the ground-breaking case challenging the facial recognition software trialled by South Wales police was upheld on appeal in the first legal case of its kind [
 <xref ref-type="bibr" rid="CR5">5</xref>]. Also, in August 2020, we saw the public uproar and legal challenge caused by the algorithm employed to predict grades for students. This clearly indicates that public awareness and impetus to hold AI systems to account is increasing. Around the same time other reports announced the withdrawal of child welfare algorithms by several councils [
 <xref ref-type="bibr" rid="CR6">6</xref>] and the suspension of the Most Serious Violence predictive system, part of the Â£10 million Home Office funded National Data Analytics Solution, by West Midlands Police on the advice of its Ethics Committee [
 <xref ref-type="bibr" rid="CR7">7</xref>]. Additionally, many cases have been heard globally and have been upheld [
 <xref ref-type="bibr" rid="CR8">8</xref>, 
 <xref ref-type="bibr" rid="CR9">9</xref>]. This clearly indicates that public awareness and impetus to hold AI systems to account is increasing.
</p>
